### Project overview

Emotion-LLaMA is structured as follows:

```
ğŸ“¦Dataset
 â”— ğŸ“¦Emotion
    â”— ğŸ“‚MER2023
      â”£ ğŸ“‚video
      â”£ ğŸ“‚HL-UTT 
      â”£ ğŸ“‚mae_340_UTT
      â”£ ğŸ“‚maeV_399_UTT
      â”£ ğŸ“„transcription_en_all.csv
      â”£ ğŸ“„MERR_coarse_grained.txt
      â”£ ğŸ“„MERR_coarse_grained.json
      â”£ ğŸ“„MERR_fine_grained.txt
      â”— ğŸ“„MERR_fine_grained.json
 ğŸ“¦Emotion-LLaMA
 â”£ ğŸ“‚checkpoints
 â”ƒ â”£ ğŸ“‚Llama-2-7b-chat-hf
 â”ƒ â”£ ğŸ“‚save_checkpoint
 â”ƒ â”ƒ â”£ ğŸ“‚stage2
 â”ƒ â”ƒ â”ƒ â”£ ğŸ”–checkpoint_best.pth
 â”ƒ â”ƒ â”ƒ â”— ğŸ“„log.txt
 â”ƒ â”ƒ â”— ğŸ”–Emoation_LLaMA.pth
 â”ƒ â”£ ğŸ“‚transformer
 â”ƒ â”ƒ â”— ğŸ“‚chinese-hubert-large
 â”ƒ â”— ğŸ”–minigptv2_checkpoint.pth
 â”£ ğŸ“‚eval_configs 
 â”ƒ â”£ ğŸ“œdemo.yaml
 â”ƒ â”£ ğŸ“œeval_emotion.yaml
 â”ƒ â”— ğŸ“œeval_emotion_EMER.yaml
 â”£ ğŸ“‚train_configs
 â”ƒ â”£ ğŸ“œEmotion-LLaMA_finetune.yaml
 â”ƒ â”— ğŸ“œminigptv2_tuning_stage_2.yaml
 â”£ ğŸ“‚minigpt4
 â”£ ğŸ“‘app.py
 â”£ ğŸ“œenvironment.yml
 â”£ ğŸ“‘eval_emotion.py
 â”£ ğŸ“‘eval_emotion_EMER.py
 â”— ğŸ“‘train.py

```